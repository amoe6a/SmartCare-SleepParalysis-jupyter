{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"/workspaces/codespaces-jupyter/data/YAAD/\"\n",
    "stimulus_descripttion_file = pd.read_excel(path + 'Stimulus_Description.xlsx')\n",
    "\n",
    "fear_video_id = stimulus_descripttion_file.query('`Target Emotion` == \"fear\"').head(1).get('Video ID').item()\n",
    "\n",
    "path_single_modal_data = path + \"RawData/Singlemodal/ECG/\"\n",
    "path_multi_modal_data = path + \"RawData/Multimodal/ECG/\"\n",
    "\n",
    "single_modal_data_files = os.listdir(path_single_modal_data)\n",
    "multi_modal_data_files = os.listdir(path_multi_modal_data)\n",
    "\n",
    "single_modal_dfs = []\n",
    "for file in single_modal_data_files:\n",
    "    if \"v\" + str(fear_video_id) in file:\n",
    "        df = pd.read_csv(path_single_modal_data + file, delimiter='\\t')\n",
    "        single_modal_dfs.append(df)\n",
    "\n",
    "multi_modal_dfs = []\n",
    "for file in multi_modal_data_files:\n",
    "    if \"v\" + str(fear_video_id) in file:\n",
    "        df = pd.read_csv(path_multi_modal_data + file, delimiter='\\t')\n",
    "        multi_modal_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_dfs_to_real_dfs(dfs) -> pd.array:\n",
    "    real_dfs = []\n",
    "    for df in dfs:\n",
    "        arr = df.columns.values\n",
    "        str_vals = arr[0].split(',')\n",
    "        real_vals = [float(each) for each in str_vals]\n",
    "        real_vals_pd = pd.array(real_vals)\n",
    "        real_dfs.append(real_vals_pd)\n",
    "    return pd.array(real_dfs)\n",
    "\n",
    "def mean_of_means(dfs) -> float:\n",
    "    t = []\n",
    "    for each in dfs:\n",
    "        t.append(each.mean())\n",
    "    return pd.array(t).mean()\n",
    "\n",
    "def min_of_mins(dfs) -> float:\n",
    "    t = []\n",
    "    for each in dfs:\n",
    "        t.append(each.min())\n",
    "    return pd.array(t).min()\n",
    "\n",
    "def max_of_maxs(dfs) -> float:\n",
    "    t = []\n",
    "    for each in dfs:\n",
    "        t.append(each.max())\n",
    "    return pd.array(t).max()\n",
    "\n",
    "def mean_of_vars(dfs) -> float:\n",
    "    t = []\n",
    "    for each in dfs:\n",
    "        t.append(each.var())\n",
    "    return pd.array(t).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_sm_dfs = str_dfs_to_real_dfs(single_modal_dfs)\n",
    "real_mm_dfs = str_dfs_to_real_dfs(multi_modal_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single refers to singlemodal data\n",
    "multi refers to multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of means single:  -18.522971550372002\n",
      "mean of means multi:  -10.029048553400726\n",
      "min of mins single:  -297.21\n",
      "min of mins multi:  -21.106\n",
      "max of maxs single:  18.678\n",
      "max of maxs multi:  8.1532\n",
      "mean of vars single:  0.13076550723324526\n",
      "mean of vars multi:  0.041651835869248255\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of means single: \", mean_of_means(real_sm_dfs))\n",
    "print(\"mean of means multi: \", mean_of_means(real_mm_dfs))\n",
    "\n",
    "print(\"min of mins single: \", min_of_mins(real_sm_dfs))\n",
    "print(\"min of mins multi: \", min_of_mins(real_mm_dfs))\n",
    "\n",
    "print(\"max of maxs single: \", max_of_maxs(real_sm_dfs))\n",
    "print(\"max of maxs multi: \", max_of_maxs(real_mm_dfs))\n",
    "\n",
    "print(\"mean of vars single: \", mean_of_vars(real_sm_dfs))\n",
    "print(\"mean of vars multi: \", mean_of_vars(real_mm_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_modal_df = []\n",
    "columns = list(range(1, 5001)) + [\"Vtype\"]\n",
    "\n",
    "# We put vtype 1 for fear sessions, and vtype 0 for everything else\n",
    "for file in single_modal_data_files:\n",
    "    df = pd.read_csv(path_single_modal_data + file, delimiter='\\t')\n",
    "    vtype = float(file.split('v')[1][0])\n",
    "\n",
    "    vtype = 1 if vtype == 7.0 else 0\n",
    "\n",
    "    rdf = str_dfs_to_real_dfs([df])[0]\n",
    "    minval = rdf.min()\n",
    "    rdf_and_vtype = pd.array([(each - minval) for each in rdf] + [vtype])\n",
    "    single_modal_df.append(rdf_and_vtype)\n",
    "single_modal_df = pd.DataFrame(single_modal_df, columns=columns)\n",
    "\n",
    "\n",
    "multi_modal_df = []\n",
    "for file in multi_modal_data_files:\n",
    "    df = pd.read_csv(path_multi_modal_data + file, delimiter='\\t')\n",
    "    vtype = float(file.split('v')[1][0])\n",
    "\n",
    "    vtype = 1 if vtype == 7.0 else 0\n",
    "\n",
    "    rdf = str_dfs_to_real_dfs([df])[0]\n",
    "    minval = rdf.min()\n",
    "    rdf_and_vtype = pd.array([(each - minval) for each in rdf] + [vtype])\n",
    "    multi_modal_df.append(rdf_and_vtype)\n",
    "multi_modal_df = pd.DataFrame(multi_modal_df, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_y = single_modal_df.Vtype\n",
    "single_X = single_modal_df[list(range(1, 5001))]\n",
    "\n",
    "multi_y = multi_modal_df.Vtype\n",
    "multi_X = multi_modal_df[list(range(1, 5001))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we train using single modal data and validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11507936507936507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "fear_detect_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "fear_detect_model.fit(single_X, single_y)\n",
    "\n",
    "val_predictions = fear_detect_model.predict(multi_X)\n",
    "print(mean_absolute_error(multi_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train using multi modal data (inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12337662337662338\n"
     ]
    }
   ],
   "source": [
    "fear_detect_model.fit(multi_X, multi_y)\n",
    "\n",
    "val_predictions = fear_detect_model.predict(single_X)\n",
    "print(mean_absolute_error(single_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training for single shows a bit less mean error\n",
    "Now, we will try to find optimal max_leaf_nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_leaves(max_leaf_nodes, train_X, train_y, val_X, val_y):\n",
    "    fear_detect_model = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes, random_state=1)\n",
    "    fear_detect_model.fit(train_X, train_y)\n",
    "\n",
    "    val_predictions = fear_detect_model.predict(val_X)\n",
    "    return mean_absolute_error(val_y, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_leaf_nodes = 10, train-single mae:  0.11507936507936507\n",
      "max_leaf_nodes = 10, train-multi mae:  0.12987012987012986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_leaf_nodes = 50, train-single mae:  0.11507936507936507\n",
      "max_leaf_nodes = 50, train-multi mae:  0.12337662337662338\n",
      "max_leaf_nodes = 100, train-single mae:  0.11507936507936507\n",
      "max_leaf_nodes = 100, train-multi mae:  0.12337662337662338\n",
      "max_leaf_nodes = 500, train-single mae:  0.11507936507936507\n",
      "max_leaf_nodes = 500, train-multi mae:  0.12337662337662338\n",
      "max_leaf_nodes = 1000, train-single mae:  0.11507936507936507\n",
      "max_leaf_nodes = 1000, train-multi mae:  0.12337662337662338\n",
      "max_leaf_nodes = 5000, train-single mae:  0.11507936507936507\n",
      "max_leaf_nodes = 5000, train-multi mae:  0.12337662337662338\n"
     ]
    }
   ],
   "source": [
    "for leaves in (10, 50, 100, 500, 1000, 5000):\n",
    "    print(f\"max_leaf_nodes = {leaves}, train-single mae: \", try_leaves(leaves, single_X, single_y, multi_X, multi_y))\n",
    "    print(f\"max_leaf_nodes = {leaves}, train-multi mae: \", try_leaves(leaves, multi_X, multi_y, single_X, single_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_leaf_node=50 with singlemodal data as training data seems to be optimal setting for current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "17\n",
      "47.22222222222222\n"
     ]
    }
   ],
   "source": [
    "fear_detect_model = DecisionTreeClassifier(max_leaf_nodes=50, random_state=1)\n",
    "\n",
    "fear_detect_model.fit(single_X, single_y)\n",
    "\n",
    "# try to test our model on fear sessions\n",
    "fear_multi_modal =  multi_modal_df.query(\"`Vtype` == 1\")\n",
    "val_X = fear_multi_modal[list(range(1, 5001))]\n",
    "val_predictions = fear_detect_model.predict(val_X)\n",
    "print(val_predictions)\n",
    "# as all of the entries in val_prediction should ideally be equal to 7.0:\n",
    "counter = 0\n",
    "for each in val_predictions:\n",
    "    if round(each, 0) == 1.0:\n",
    "        counter += 1\n",
    "print(counter)\n",
    "# getting the % of correct answers:\n",
    "print(100* (counter / len(val_predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy is 47%\n",
    "TT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try another model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
